{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw0EQftIuY01jHE+exLoHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshmukhiya/Topic-Modeling-NMF/blob/main/cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EQMUF1gKoaAe"
      },
      "outputs": [],
      "source": [
        "#Import Required Libraries\n",
        "import numpy as np\n",
        "from sklearn.decomposition import NMF, TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorize the Data\n",
        "# Load the dataset (fetch_20newsgroups)\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes')).data\n",
        "\n",
        "# Preprocess and vectorize the data\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X = vectorizer.fit_transform(data)"
      ],
      "metadata": {
        "id": "_Zj9ZAQFojWA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the Cross-Validation Procedure\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold cross-validation\n"
      ],
      "metadata": {
        "id": "cSMxcCL2otJo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Topic Models\n",
        "n_topics = 5\n",
        "nmf = NMF(n_components=n_topics, random_state=1)\n",
        "svd = TruncatedSVD(n_components=n_topics, random_state=1)\n",
        "lda = LDA(n_components=n_topics, random_state=1)\n"
      ],
      "metadata": {
        "id": "GQ7nZTIvo143"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform Cross-Validation\n",
        "nmf_coherence_scores = []\n",
        "svd_coherence_scores = []\n",
        "lda_coherence_scores = []\n",
        "\n",
        "for train_index, test_index in kfold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "\n",
        "    # Fit NMF\n",
        "    W_train = nmf.fit_transform(X_train)\n",
        "    H = nmf.components_\n",
        "\n",
        "    # Fit SVD\n",
        "    svd.fit(X_train)\n",
        "    svd_topics = svd.components_\n",
        "\n",
        "    # Fit LDA\n",
        "    lda.fit(X_train)\n",
        "    lda_topics = lda.components_\n",
        "\n",
        "    # Get top words for each model\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    nmf_top_words = [[feature_names[i] for i in topic.argsort()[:-11:-1]] for topic in H]\n",
        "    svd_top_words = [[feature_names[i] for i in topic.argsort()[:-11:-1]] for topic in svd_topics]\n",
        "    lda_top_words = [[feature_names[i] for i in topic.argsort()[:-11:-1]] for topic in lda_topics]\n",
        "\n",
        "    # Convert documents to a list of words (simple tokenization)\n",
        "    texts = [simple_preprocess(doc) for doc in data]\n",
        "    dictionary = Dictionary(texts)\n",
        "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "    # Calculate coherence score for NMF\n",
        "    coherence_model_nmf = CoherenceModel(topics=nmf_top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    nmf_coherence_scores.append(coherence_model_nmf.get_coherence())\n",
        "\n",
        "    # Calculate coherence score for SVD\n",
        "    coherence_model_svd = CoherenceModel(topics=svd_top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    svd_coherence_scores.append(coherence_model_svd.get_coherence())\n",
        "\n",
        "    # Calculate coherence score for LDA\n",
        "    coherence_model_lda = CoherenceModel(topics=lda_top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    lda_coherence_scores.append(coherence_model_lda.get_coherence())\n"
      ],
      "metadata": {
        "id": "1c3cM3h7o75_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Average Coherence Scores\n",
        "print(f\"Average NMF Coherence Score: {np.mean(nmf_coherence_scores)}\")\n",
        "print(f\"Average SVD Coherence Score: {np.mean(svd_coherence_scores)}\")\n",
        "print(f\"Average LDA Coherence Score: {np.mean(lda_coherence_scores)}\")\n"
      ],
      "metadata": {
        "id": "ck_9aFWCpI3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d9fffd-8045-41d9-88db-f06d80250d75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average NMF Coherence Score: 0.6850835781610958\n",
            "Average SVD Coherence Score: 0.5063859855274969\n",
            "Average LDA Coherence Score: 0.526716650730926\n"
          ]
        }
      ]
    }
  ]
}