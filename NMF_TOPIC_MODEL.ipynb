{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU4/7nEa+0Bn272XwLng6U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshmukhiya/Topic-Modeling-NMF/blob/main/NMF_TOPIC_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u3VntKswRvXy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the data\n",
        "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "0RpIwaQUR1SF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: View initial raw data\n",
        "print(\"Raw Text Data Example:\")\n",
        "print(train_data.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_QIoPPoSBUG",
        "outputId": "455c6b4b-e336-49c0-8f68-498658c5be7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Text Data Example:\n",
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Preprocessing: Cleaned text (you can implement additional custom preprocessing)\n",
        "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
        "X_train = vectorizer.fit_transform(train_data.data)"
      ],
      "metadata": {
        "id": "ebTYAe_ZSF71"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: View a sample of the TF-IDF matrix\n",
        "print(\"\\nTF-IDF Matrix Shape:\", X_train.shape)\n",
        "print(\"TF-IDF Matrix Sample (First Document):\")\n",
        "print(X_train[0])\n",
        "\n",
        "# Print the actual topic terms for the most dominant topic\n",
        "#feature_names = vectorizer.get_feature_names_out()\n",
        "#dominant_topic_terms = [feature_names[i] for i in H[dominant_topic].argsort()[:-11:-1]]\n",
        "#print(f\"Top words for the dominant topic: {', '.join(dominant_topic_terms)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTh410F4STk4",
        "outputId": "c07f59bd-e4f6-4413-85de-1f93463d5d66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Matrix Shape: (11314, 101322)\n",
            "TF-IDF Matrix Sample (First Document):\n",
            "  (0, 9843)\t0.20797700857530224\n",
            "  (0, 11174)\t0.20599311323287353\n",
            "  (0, 16806)\t0.1407774554706102\n",
            "  (0, 23430)\t0.12937103288512333\n",
            "  (0, 24108)\t0.24723134514216435\n",
            "  (0, 24583)\t0.19644480500804062\n",
            "  (0, 25437)\t0.10548299054214269\n",
            "  (0, 25717)\t0.46579831435138974\n",
            "  (0, 31927)\t0.10526008886822914\n",
            "  (0, 34741)\t0.14847880131844235\n",
            "  (0, 34742)\t0.17300821242559045\n",
            "  (0, 35902)\t0.1266709604197344\n",
            "  (0, 37208)\t0.1434127293323407\n",
            "  (0, 37256)\t0.20599311323287353\n",
            "  (0, 41874)\t0.224548896412017\n",
            "  (0, 46690)\t0.12504220873599214\n",
            "  (0, 49800)\t0.11869932893481257\n",
            "  (0, 54493)\t0.06961997844491917\n",
            "  (0, 55606)\t0.13822596989753821\n",
            "  (0, 57247)\t0.1352084247105906\n",
            "  (0, 57250)\t0.1063473585616558\n",
            "  (0, 59071)\t0.10043853867312116\n",
            "  (0, 62594)\t0.13037295035007848\n",
            "  (0, 73174)\t0.16142029533900565\n",
            "  (0, 76269)\t0.08978258481915573\n",
            "  (0, 77676)\t0.12197186951739486\n",
            "  (0, 80420)\t0.127069039671221\n",
            "  (0, 81450)\t0.1461308934288897\n",
            "  (0, 83208)\t0.11339406589538423\n",
            "  (0, 84050)\t0.16329311028814825\n",
            "  (0, 84312)\t0.16368392505928514\n",
            "  (0, 87913)\t0.25808578247347563\n",
            "  (0, 96879)\t0.13703598126117264\n",
            "  (0, 99608)\t0.09418459052541318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply NMF\n",
        "nmf = NMF(n_components=20, random_state=1)\n",
        "W_train = nmf.fit_transform(X_train)\n",
        "H = nmf.components_"
      ],
      "metadata": {
        "id": "6E6iPb-0SXBR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: View the W matrix (Document-Topic Matrix)\n",
        "print(\"\\nW Matrix Shape:\", W_train.shape)\n",
        "print(\"W Matrix Sample (First Document):\")\n",
        "print(W_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw5BUQ3vSiWI",
        "outputId": "16045661-0ce6-4913-977b-4c99f6869eee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "W Matrix Shape: (11314, 20)\n",
            "W Matrix Sample (First Document):\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.03227418 0.1458308  0.         0.         0.\n",
            " 0.         0.00085594 0.01571497 0.         0.         0.\n",
            " 0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: View the H matrix (Topic-Term Matrix)\n",
        "print(\"\\nH Matrix Shape:\", H.shape)\n",
        "print(\"H Matrix Sample (First Topic):\")\n",
        "print(H[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5186D-pkSput",
        "outputId": "23abb81a-d8e9-497f-b852-625cb302845f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "H Matrix Shape: (20, 101322)\n",
            "H Matrix Sample (First Topic):\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume X_train is the TF-IDF matrix obtained from preprocessing\n",
        "# Set the number of topics\n",
        "n_topics = 5"
      ],
      "metadata": {
        "id": "gi_aZivgTKrH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply NMF\n",
        "nmf = NMF(n_components=n_topics, random_state=1)\n",
        "W_train = nmf.fit_transform(X_train)\n",
        "H = nmf.components_"
      ],
      "metadata": {
        "id": "uPhcym5wTYr9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the top words for each topic\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "for topic_idx, topic in enumerate(H):\n",
        "    top_terms = [feature_names[i] for i in topic.argsort()[:-11:-1]]  # Top 10 terms\n",
        "    print(f\"Topic #{topic_idx+1}: {', '.join(top_terms)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9PGP4tgTj7n",
        "outputId": "328026b7-71ed-4d6d-cbc7-a8eafdb98f90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1: don, people, just, think, like, good, know, time, right, did\n",
            "Topic #2: windows, thanks, drive, card, does, dos, use, file, know, mail\n",
            "Topic #3: god, jesus, bible, believe, faith, christian, christians, christ, does, people\n",
            "Topic #4: geb, dsl, pitt, chastity, n3jxp, cadre, shameful, intellect, skepticism, surrender\n",
            "Topic #5: key, chip, encryption, clipper, keys, government, escrow, algorithm, use, law\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "4o-bPRUcWF7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you already have the TF-IDF matrix `X_train` and the original training data `train_data`\n",
        "n_topics = 5"
      ],
      "metadata": {
        "id": "jkfVwSbYWJc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply NMF\n",
        "nmf = NMF(n_components=n_topics, random_state=1)\n",
        "W_train = nmf.fit_transform(X_train)\n",
        "H = nmf.components_"
      ],
      "metadata": {
        "id": "FItZStGfWN7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the top words for each topic\n",
        "top_words = []\n",
        "for topic_idx, topic in enumerate(H):\n",
        "    top_terms = [feature_names[i] for i in topic.argsort()[:-11:-1]]  # Top 10 terms\n",
        "    top_words.append(top_terms)"
      ],
      "metadata": {
        "id": "46W4c7rJWVot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for Gensim\n",
        "# Convert documents to a list of words (simple tokenization)\n",
        "texts = [simple_preprocess(doc) for doc in train_data.data]"
      ],
      "metadata": {
        "id": "XpmLUYdKWZy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary representation of the documents\n",
        "dictionary = Dictionary(texts)"
      ],
      "metadata": {
        "id": "Un4hiviRWc1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert documents to bag-of-words format\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "DueeXX27WgD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate coherence score\n",
        "coherence_model_nmf = CoherenceModel(topics=top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_score = coherence_model_nmf.get_coherence()\n",
        "\n",
        "print(f\"NMF Model Coherence Score: {coherence_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfWhSQDJWkH-",
        "outputId": "a2bae0f0-8454-4433-f154-1272aef91fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Model Coherence Score: 0.743156067277227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTMDRqCYcqdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Fetch the data\n",
        "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Vectorize the data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_data.data)\n",
        "\n",
        "# Set the number of topics\n",
        "n_topics = 5\n",
        "\n",
        "# Apply NMF\n",
        "nmf = NMF(n_components=n_topics, random_state=1)\n",
        "W_train = nmf.fit_transform(X_train)\n",
        "H = nmf.components_\n",
        "\n",
        "# Extract and display the latent topics\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "for topic_idx, topic in enumerate(H):\n",
        "    top_terms = [feature_names[i] for i in topic.argsort()[:-11:-1]]  # Top 10 terms\n",
        "    print(f\"Topic #{topic_idx+1}: {', '.join(top_terms)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5xmnSO5cqaI",
        "outputId": "634936b9-ebd9-4811-ed72-b08b1112ab84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1: don, people, just, think, like, good, know, time, right, did\n",
            "Topic #2: windows, thanks, drive, card, does, dos, use, file, know, mail\n",
            "Topic #3: god, jesus, bible, believe, faith, christian, christians, christ, does, people\n",
            "Topic #4: geb, dsl, pitt, chastity, n3jxp, cadre, shameful, intellect, skepticism, surrender\n",
            "Topic #5: key, chip, encryption, clipper, keys, government, escrow, algorithm, use, law\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Topic selection Using NMF"
      ],
      "metadata": {
        "id": "_0Y59HNRfWIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Fetch the data\n",
        "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Vectorize the data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_data.data)\n",
        "\n",
        "# Set the number of topics\n",
        "n_topics = 5\n",
        "\n",
        "# Apply NMF\n",
        "nmf = NMF(n_components=n_topics, random_state=1)\n",
        "W_train = nmf.fit_transform(X_train)\n",
        "H = nmf.components_\n",
        "\n",
        "# Extract and display the latent topics (only one word per topic)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "for topic_idx, topic in enumerate(H):\n",
        "    top_term = feature_names[topic.argmax()]  # Only the top term\n",
        "    print(f\"Topic #{topic_idx+1}: {top_term}\")\n"
      ],
      "metadata": {
        "id": "hi-8fwaZfVUc",
        "outputId": "e5d91177-4d3d-4ee8-c002-b92ad198242e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1: don\n",
            "Topic #2: windows\n",
            "Topic #3: god\n",
            "Topic #4: geb\n",
            "Topic #5: key\n"
          ]
        }
      ]
    }
  ]
}